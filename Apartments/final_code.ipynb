{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "\n",
    "np.random.seed(2137) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_id</th>\n",
       "      <th>obj_type</th>\n",
       "      <th>dim_m2</th>\n",
       "      <th>n_rooms</th>\n",
       "      <th>floor_no</th>\n",
       "      <th>floor_max</th>\n",
       "      <th>year_built</th>\n",
       "      <th>dist_centre</th>\n",
       "      <th>n_poi</th>\n",
       "      <th>dist_sch</th>\n",
       "      <th>dist_clinic</th>\n",
       "      <th>dist_post</th>\n",
       "      <th>dist_kind</th>\n",
       "      <th>dist_rest</th>\n",
       "      <th>dist_uni</th>\n",
       "      <th>dist_pharma</th>\n",
       "      <th>own_type</th>\n",
       "      <th>build_mat</th>\n",
       "      <th>cond_class</th>\n",
       "      <th>has_park</th>\n",
       "      <th>has_balcony</th>\n",
       "      <th>has_lift</th>\n",
       "      <th>has_sec</th>\n",
       "      <th>has_store</th>\n",
       "      <th>price_z</th>\n",
       "      <th>src_month</th>\n",
       "      <th>loc_code</th>\n",
       "      <th>market_volatility</th>\n",
       "      <th>infrastructure_quality</th>\n",
       "      <th>neighborhood_crime_rate</th>\n",
       "      <th>popularity_index</th>\n",
       "      <th>green_space_ratio</th>\n",
       "      <th>estimated_maintenance_cost</th>\n",
       "      <th>global_economic_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24270</th>\n",
       "      <td>78a1de0708226437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.83</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>7.846</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.629</td>\n",
       "      <td>1.739</td>\n",
       "      <td>0.101</td>\n",
       "      <td>12631efb</td>\n",
       "      <td>7ceffe3b</td>\n",
       "      <td>53cced8d</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>704287.28</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>693f303c</td>\n",
       "      <td>800711.71</td>\n",
       "      <td>32.67</td>\n",
       "      <td>48.48</td>\n",
       "      <td>62.38</td>\n",
       "      <td>0.999</td>\n",
       "      <td>9.04</td>\n",
       "      <td>105.668549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83142</th>\n",
       "      <td>115a285f1e8bbc20</td>\n",
       "      <td>0d6c4dfc</td>\n",
       "      <td>35.53</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>3.960</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.294</td>\n",
       "      <td>2.154</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.255</td>\n",
       "      <td>12631efb</td>\n",
       "      <td>7f8c00f9</td>\n",
       "      <td>53cced8d</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>313238.60</td>\n",
       "      <td>2023-08</td>\n",
       "      <td>8d5a4f0c</td>\n",
       "      <td>258100.50</td>\n",
       "      <td>37.87</td>\n",
       "      <td>26.23</td>\n",
       "      <td>48.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.88</td>\n",
       "      <td>104.927936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33582</th>\n",
       "      <td>a76803b46f21fb29</td>\n",
       "      <td>0d6c4dfc</td>\n",
       "      <td>25.87</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>6.563</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.090</td>\n",
       "      <td>1.316</td>\n",
       "      <td>0.061</td>\n",
       "      <td>12631efb</td>\n",
       "      <td>7ceffe3b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>493304.86</td>\n",
       "      <td>2024-04</td>\n",
       "      <td>e0cff11b</td>\n",
       "      <td>409311.56</td>\n",
       "      <td>75.92</td>\n",
       "      <td>17.89</td>\n",
       "      <td>50.33</td>\n",
       "      <td>0.999</td>\n",
       "      <td>12.23</td>\n",
       "      <td>90.167666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>6424c0db2a193b6b</td>\n",
       "      <td>0d6c4dfc</td>\n",
       "      <td>58.98</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>4.714</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.317</td>\n",
       "      <td>2.250</td>\n",
       "      <td>1.087</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.152</td>\n",
       "      <td>2.146</td>\n",
       "      <td>0.569</td>\n",
       "      <td>12631efb</td>\n",
       "      <td>7ceffe3b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1991412.59</td>\n",
       "      <td>2023-10</td>\n",
       "      <td>693f303c</td>\n",
       "      <td>2008616.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.01</td>\n",
       "      <td>38.72</td>\n",
       "      <td>1.000</td>\n",
       "      <td>23.90</td>\n",
       "      <td>94.343251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>390664e65d2bd159</td>\n",
       "      <td>0c238f18</td>\n",
       "      <td>51.72</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.593</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.023</td>\n",
       "      <td>12631efb</td>\n",
       "      <td>7ceffe3b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>583340.31</td>\n",
       "      <td>2023-08</td>\n",
       "      <td>0ab06839</td>\n",
       "      <td>497593.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.23</td>\n",
       "      <td>35.79</td>\n",
       "      <td>1.000</td>\n",
       "      <td>9.70</td>\n",
       "      <td>104.708779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38195</th>\n",
       "      <td>467a68c5b1e2a638</td>\n",
       "      <td>0c238f18</td>\n",
       "      <td>44.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>1.315</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.452</td>\n",
       "      <td>12631efb</td>\n",
       "      <td>7ceffe3b</td>\n",
       "      <td>a2881958</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>696695.01</td>\n",
       "      <td>2023-11</td>\n",
       "      <td>693f303c</td>\n",
       "      <td>760572.57</td>\n",
       "      <td>78.62</td>\n",
       "      <td>54.11</td>\n",
       "      <td>69.87</td>\n",
       "      <td>1.000</td>\n",
       "      <td>6.46</td>\n",
       "      <td>95.629116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77428</th>\n",
       "      <td>223961fb32c9f378</td>\n",
       "      <td>2a6d5c01</td>\n",
       "      <td>55.91</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>0.251</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.249</td>\n",
       "      <td>12631efb</td>\n",
       "      <td>7ceffe3b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1372652.41</td>\n",
       "      <td>2024-06</td>\n",
       "      <td>e0cff11b</td>\n",
       "      <td>1552494.92</td>\n",
       "      <td>1.30</td>\n",
       "      <td>53.47</td>\n",
       "      <td>69.91</td>\n",
       "      <td>1.000</td>\n",
       "      <td>7.97</td>\n",
       "      <td>107.830152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66138</th>\n",
       "      <td>d405785608a95062</td>\n",
       "      <td>0d6c4dfc</td>\n",
       "      <td>75.11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>16.980</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686</td>\n",
       "      <td>12631efb</td>\n",
       "      <td>7ceffe3b</td>\n",
       "      <td>a2881958</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>520878.21</td>\n",
       "      <td>2023-08</td>\n",
       "      <td>693f303c</td>\n",
       "      <td>522689.71</td>\n",
       "      <td>8.24</td>\n",
       "      <td>94.83</td>\n",
       "      <td>64.45</td>\n",
       "      <td>0.998</td>\n",
       "      <td>24.96</td>\n",
       "      <td>105.255044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17399</th>\n",
       "      <td>531952a298de2f42</td>\n",
       "      <td>0d6c4dfc</td>\n",
       "      <td>35.35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>1.664</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.468</td>\n",
       "      <td>1.633</td>\n",
       "      <td>0.381</td>\n",
       "      <td>12631efb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>373127.46</td>\n",
       "      <td>2024-01</td>\n",
       "      <td>e0cff11b</td>\n",
       "      <td>381721.48</td>\n",
       "      <td>81.90</td>\n",
       "      <td>2.16</td>\n",
       "      <td>55.92</td>\n",
       "      <td>1.000</td>\n",
       "      <td>6.67</td>\n",
       "      <td>92.882208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81945</th>\n",
       "      <td>cd4b403eca3297f4</td>\n",
       "      <td>2a6d5c01</td>\n",
       "      <td>77.95</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>4.882</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.266</td>\n",
       "      <td>2.365</td>\n",
       "      <td>0.062</td>\n",
       "      <td>12631efb</td>\n",
       "      <td>7ceffe3b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1689740.47</td>\n",
       "      <td>2023-12</td>\n",
       "      <td>693f303c</td>\n",
       "      <td>1812499.92</td>\n",
       "      <td>2.06</td>\n",
       "      <td>20.78</td>\n",
       "      <td>44.19</td>\n",
       "      <td>1.000</td>\n",
       "      <td>14.79</td>\n",
       "      <td>93.899531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                unit_id  obj_type  dim_m2  n_rooms  floor_no  floor_max  \\\n",
       "24270  78a1de0708226437       NaN   48.83      2.0       1.0        3.0   \n",
       "83142  115a285f1e8bbc20  0d6c4dfc   35.53      2.0       3.0        4.0   \n",
       "33582  a76803b46f21fb29  0d6c4dfc   25.87      2.0       3.0        4.0   \n",
       "1257   6424c0db2a193b6b  0d6c4dfc   58.98      3.0       NaN        3.0   \n",
       "9115   390664e65d2bd159  0c238f18   51.72      2.0       3.0        3.0   \n",
       "38195  467a68c5b1e2a638  0c238f18   44.99      2.0       3.0        6.0   \n",
       "77428  223961fb32c9f378  2a6d5c01   55.91      3.0       5.0        6.0   \n",
       "66138  d405785608a95062  0d6c4dfc   75.11      4.0       3.0        3.0   \n",
       "17399  531952a298de2f42  0d6c4dfc   35.35      1.0       NaN        3.0   \n",
       "81945  cd4b403eca3297f4  2a6d5c01   77.95      4.0      10.0       12.0   \n",
       "\n",
       "       year_built  dist_centre  n_poi  dist_sch  dist_clinic  dist_post  \\\n",
       "24270      1998.0        7.846   11.0     0.234        0.171      0.623   \n",
       "83142      1970.0        3.960    8.0     0.294        2.154      0.848   \n",
       "33582      1963.0        6.563   23.0     0.267        0.552      0.074   \n",
       "1257       2022.0        4.714   10.0     0.317        2.250      1.087   \n",
       "9115          NaN        0.593  121.0     0.016        0.108      0.258   \n",
       "38195      1961.0        1.315   81.0     0.133        0.535      0.173   \n",
       "77428      2023.0        0.251   98.0     0.495        0.728      0.312   \n",
       "66138      2011.0       16.980    2.0     0.758          NaN      0.720   \n",
       "17399      1965.0        1.664    9.0     0.278        0.783      0.223   \n",
       "81945      2020.0        4.882   17.0     0.355        0.112      0.135   \n",
       "\n",
       "       dist_kind  dist_rest  dist_uni  dist_pharma  own_type build_mat  \\\n",
       "24270      0.222      0.629     1.739        0.101  12631efb  7ceffe3b   \n",
       "83142      0.286      0.268     0.316        0.255  12631efb  7f8c00f9   \n",
       "33582      0.329      0.090     1.316        0.061  12631efb  7ceffe3b   \n",
       "1257       0.264      0.152     2.146        0.569  12631efb  7ceffe3b   \n",
       "9115       0.100      0.026     0.111        0.023  12631efb  7ceffe3b   \n",
       "38195      0.425      0.015     0.305        0.452  12631efb  7ceffe3b   \n",
       "77428      0.265      0.040     0.946        0.249  12631efb  7ceffe3b   \n",
       "66138      0.273      0.364       NaN        0.686  12631efb  7ceffe3b   \n",
       "17399      0.778      0.468     1.633        0.381  12631efb       NaN   \n",
       "81945      0.322      0.266     2.365        0.062  12631efb  7ceffe3b   \n",
       "\n",
       "      cond_class has_park has_balcony has_lift has_sec has_store     price_z  \\\n",
       "24270   53cced8d      yes         yes       no      no       yes   704287.28   \n",
       "83142   53cced8d       no          no       no      no       yes   313238.60   \n",
       "33582        NaN       no         yes       no      no       yes   493304.86   \n",
       "1257         NaN       no         yes      yes      no        no  1991412.59   \n",
       "9115         NaN       no          no       no      no        no   583340.31   \n",
       "38195   a2881958       no          no      yes      no        no   696695.01   \n",
       "77428        NaN       no          no      yes      no        no  1372652.41   \n",
       "66138   a2881958       no         yes       no     yes        no   520878.21   \n",
       "17399        NaN       no          no       no      no       yes   373127.46   \n",
       "81945        NaN       no          no      yes      no        no  1689740.47   \n",
       "\n",
       "      src_month  loc_code  market_volatility  infrastructure_quality  \\\n",
       "24270   2024-03  693f303c          800711.71                   32.67   \n",
       "83142   2023-08  8d5a4f0c          258100.50                   37.87   \n",
       "33582   2024-04  e0cff11b          409311.56                   75.92   \n",
       "1257    2023-10  693f303c         2008616.80                    1.00   \n",
       "9115    2023-08  0ab06839          497593.97                     NaN   \n",
       "38195   2023-11  693f303c          760572.57                   78.62   \n",
       "77428   2024-06  e0cff11b         1552494.92                    1.30   \n",
       "66138   2023-08  693f303c          522689.71                    8.24   \n",
       "17399   2024-01  e0cff11b          381721.48                   81.90   \n",
       "81945   2023-12  693f303c         1812499.92                    2.06   \n",
       "\n",
       "       neighborhood_crime_rate  popularity_index  green_space_ratio  \\\n",
       "24270                    48.48             62.38              0.999   \n",
       "83142                    26.23             48.00              1.000   \n",
       "33582                    17.89             50.33              0.999   \n",
       "1257                      3.01             38.72              1.000   \n",
       "9115                     92.23             35.79              1.000   \n",
       "38195                    54.11             69.87              1.000   \n",
       "77428                    53.47             69.91              1.000   \n",
       "66138                    94.83             64.45              0.998   \n",
       "17399                     2.16             55.92              1.000   \n",
       "81945                    20.78             44.19              1.000   \n",
       "\n",
       "       estimated_maintenance_cost  global_economic_index  \n",
       "24270                        9.04             105.668549  \n",
       "83142                        3.88             104.927936  \n",
       "33582                       12.23              90.167666  \n",
       "1257                        23.90              94.343251  \n",
       "9115                         9.70             104.708779  \n",
       "38195                        6.46              95.629116  \n",
       "77428                        7.97             107.830152  \n",
       "66138                       24.96             105.255044  \n",
       "17399                        6.67              92.882208  \n",
       "81945                       14.79              93.899531  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('appartments_train.csv')\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['cond_class', 'build_mat', 'green_space_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting \"obj_type\" to 'other\" if its missing\n",
    "df['obj_type'] = df['obj_type'].fillna('other')\n",
    "\n",
    "# using median value (4) for max floor if its missing\n",
    "df['floor_max'] = df['floor_max'].fillna(4)\n",
    "\n",
    "# if there is no floor, choose mid of the building\n",
    "df['floor_no'] = df['floor_no'].fillna(df['floor_max']/2)\n",
    "\n",
    "# for all distances I'll use the average of mean and median\n",
    "dist_columns = ['dist_centre', 'dist_sch','dist_clinic','dist_post', 'dist_kind',\n",
    "                'dist_rest', 'dist_uni', 'dist_pharma']\n",
    "\n",
    "for col in dist_columns:\n",
    "    avg_mean_median = (df[col].mean() + df[col].median()) / 2\n",
    "    df[col] = df[col].fillna(avg_mean_median)\n",
    "\n",
    "# managing all \"has..\" variables. If null happens - we will code it as \"no\". Then change into boolean\n",
    "has_columns = ['has_park', 'has_balcony', 'has_lift', 'has_sec', 'has_store']\n",
    "\n",
    "for col in has_columns:\n",
    "    df[col] = df[col].fillna('no')\n",
    "    df[col] = df[col].map({'no':0, 'yes':1})\n",
    "\n",
    "\n",
    "# dealing with other measures. If NA happen, I will use average of mean and median (to mitigate outliers). \n",
    "\n",
    "other_measures = ['market_volatility', 'infrastructure_quality', 'neighborhood_crime_rate', 'popularity_index',\n",
    "                'estimated_maintenance_cost', 'global_economic_index']\n",
    "\n",
    "for col in other_measures:\n",
    "    avg_mean_median = (df[col].mean() + df[col].median()) / 2\n",
    "    df[col] = df[col].fillna(avg_mean_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Step 1: Identify indices\n",
    "known_mask = df['year_built'].notna()\n",
    "missing_mask = df['year_built'].isna()\n",
    "\n",
    "# Step 2: Define features\n",
    "features = ['floor_no', 'floor_max', 'n_rooms', 'dim_m2', 'dist_centre', 'obj_type',\n",
    "            'price_z', 'infrastructure_quality', 'has_lift', 'estimated_maintenance_cost']\n",
    "\n",
    "# Step 3: Prepare known data\n",
    "df_known = df.loc[known_mask, features + ['year_built']].copy()\n",
    "X_known = pd.get_dummies(df_known[features])\n",
    "y_known = df_known['year_built']\n",
    "\n",
    "# Step 4: Prepare missing data (use same dummies structure!)\n",
    "df_missing = df.loc[missing_mask, features].copy()\n",
    "X_missing = pd.get_dummies(df_missing)\n",
    "\n",
    "# Step 5: Align columns in case of missing dummy columns in either set\n",
    "X_missing = X_missing.reindex(columns=X_known.columns, fill_value=0)\n",
    "\n",
    "# Step 6: Train model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_known, y_known)\n",
    "\n",
    "# Step 7: Predict and impute\n",
    "df.loc[missing_mask, 'year_built'] = rf.predict(X_missing).round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['src_month'] = pd.to_datetime(df['src_month'], format='%Y-%m')\n",
    "df['src_year'] = df['src_month'].dt.year\n",
    "df['src_month'] = df['src_month'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if apartment is on the last floor\n",
    "df['last_floor'] = np.where(df['floor_no'] == df['floor_max'], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['room_size'] = df['dim_m2'] / df['n_rooms']\n",
    "\n",
    "df['apart_age'] = df['src_year'] - df['year_built']\n",
    "\n",
    "df['is_old_building'] = np.where((df['apart_age'] >= 100), 1, 0)\n",
    "df['is_new_building'] = np.where((df['apart_age'] <= 10), 1, 0)\n",
    "\n",
    "df['has_all_amenities'] = np.where((df['has_park'] == 1) & (df['has_balcony'] == 1) & (df['has_lift'] == 1) & (df['has_sec'] == 1), 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "vars_to_transform = [\n",
    "    'dist_centre', 'dist_uni', 'infrastructure_quality',\n",
    "    'estimated_maintenance_cost', 'dist_clinic', 'dist_post', 'dist_sch',\n",
    "    'dist_pharma', 'dist_kind', 'dist_rest', 'n_poi', 'room_size', 'apart_age'\n",
    "]\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "df[vars_to_transform] = pt.fit_transform(df[vars_to_transform])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA component loadings (positive → further, negative → closer):\n",
      "n_poi         -0.438512\n",
      "dist_kind      0.241474\n",
      "dist_centre    0.296308\n",
      "dist_uni       0.317427\n",
      "dist_post      0.318704\n",
      "dist_clinic    0.321495\n",
      "dist_sch       0.341227\n",
      "dist_pharma    0.343904\n",
      "dist_rest      0.348141\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Define distance-related variables\n",
    "distance_vars = [\n",
    "    'dist_centre', 'dist_sch', 'dist_clinic', 'dist_post', 'dist_kind',\n",
    "    'dist_rest', 'dist_uni', 'dist_pharma', 'n_poi'\n",
    "]\n",
    "\n",
    "# Extract data for PCA\n",
    "X_dist = df[distance_vars]\n",
    "\n",
    "# Standardize the distance variables\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_dist)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=1)\n",
    "accessibility_scores = pca.fit_transform(X_scaled).ravel()\n",
    "\n",
    "# Assign meta-variable back to the original DataFrame\n",
    "df['overall_accessibility'] = accessibility_scores\n",
    "\n",
    "# Show contribution of each feature to the PCA component\n",
    "print(\"PCA component loadings (positive → further, negative → closer):\")\n",
    "print(pd.Series(pca.components_[0], index=distance_vars).sort_values())\n",
    "\n",
    "df = df.drop(distance_vars, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_price'] = np.log(df['price_z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turing year into categorical and one hot encoding. Dropping first to omit collinearity\n",
    "\n",
    "bins = [0, 1900, 1920, 1940, 1950, 1960, 1970, 1980, 1990, 2000, 2010, 2020, 2030]\n",
    "labels = [\n",
    "    'before_1900', '1900_1920', '1920_1940', '1940_1950', '1950_1960', '1960_1970',\n",
    "    '1970_1980', '1980_1990', '1990_2000', '2000_2010', '2010_2020', 'after_2020'\n",
    "]\n",
    "\n",
    "df['year_built_cat'] = pd.cut(df['year_built'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "df = pd.get_dummies(df, columns=['year_built_cat'], prefix='', prefix_sep='', drop_first=True)\n",
    "\n",
    "\n",
    "df = df.drop(columns=['year_built'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turing obj_type into dummies - only 4 options\n",
    "df = pd.get_dummies(df, columns=['obj_type'], prefix='obj_type', drop_first=True)\n",
    "\n",
    "# similar for own_type\n",
    "df = pd.get_dummies(df, columns=['own_type'], prefix='own_type', drop_first=True)\n",
    "\n",
    "# and finally for loc_code\n",
    "df = pd.get_dummies(df, columns=['loc_code'], prefix='loc_code', drop_first=True)\n",
    "\n",
    "# and for src_year, why not\n",
    "df = pd.get_dummies(df, columns=['src_year'], prefix='src_year', drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes:\n",
      "Train: (109517, 55)\n",
      "Validation: (23468, 55)\n",
      "Test: (23469, 55)\n",
      "\n",
      "Missing value counts:\n",
      "Training set: 0 missing values\n",
      "Validation set: 0 missing values\n",
      "Test set: 0 missing values\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target variable\n",
    "X = df.drop(columns=['price_z', 'log_price'])  # All features except targetget\n",
    "y = df['price_z']  # Target variable\n",
    "\n",
    "# Initial split: 70% training, 30% temporary holdout (stratified)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.30, \n",
    "    random_state=420  # Reproducibility\n",
    ")\n",
    "\n",
    "# Split temporary holdout into validation and test sets (50/50 of the 30%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, \n",
    "    y_temp, \n",
    "    test_size=0.50, \n",
    "    random_state=69  # Reproducibility\n",
    ")\n",
    "\n",
    "# Print dataset sizes for verification\n",
    "print(f\"Dataset sizes:\")\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Validation: {X_val.shape}\")\n",
    "print(f\"Test: {X_test.shape}\")\n",
    "\n",
    "# Check for missing values in each dataset\n",
    "print(\"\\nMissing value counts:\")\n",
    "print(f\"Training set: {X_train.isna().sum().sum()} missing values\")\n",
    "print(f\"Validation set: {X_val.isna().sum().sum()} missing values\")\n",
    "print(f\"Test set: {X_test.isna().sum().sum()} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "\n",
    "to_scale = [\n",
    "    'dim_m2', 'n_rooms', 'floor_no', 'floor_max', 'src_month',\n",
    "    'market_volatility', 'infrastructure_quality', 'neighborhood_crime_rate',\n",
    "    'popularity_index', 'estimated_maintenance_cost', 'global_economic_index',\n",
    "    'overall_accessibility', 'room_size', 'apart_age'\n",
    "]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Fit scaler on training data\n",
    "scaler = StandardScaler()\n",
    "X_train[to_scale] = scaler.fit_transform(X_train[to_scale])\n",
    "\n",
    "# Step 2: Transform validation and test data with the same scaler\n",
    "X_val[to_scale] = scaler.transform(X_val[to_scale])\n",
    "X_test[to_scale] = scaler.transform(X_test[to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "def train_and_tune_regressor(model, param_grid, X_train, y_train, X_val, y_val, \n",
    "                             model_name='Model', cv=5, n_jobs=-1, verbose=1):\n",
    "    \"\"\"\n",
    "    Trains and tunes a regression model using GridSearchCV.\n",
    "    \n",
    "    Args:\n",
    "        model: Base regressor model\n",
    "        param_grid: Dictionary of hyperparameters to tune\n",
    "        X_train: Training features\n",
    "        y_train: Training target\n",
    "        X_val: Validation features\n",
    "        y_val: Validation target\n",
    "        model_name: Name for model identification\n",
    "        cv: Number of cross-validation folds\n",
    "        n_jobs: Number of jobs to run in parallel\n",
    "        verbose: Controls verbosity\n",
    "        \n",
    "    Returns:\n",
    "        best_estimator: The best performing model from GridSearchCV\n",
    "        results: Dictionary with evaluation metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create scoring dictionary\n",
    "    scoring = {\n",
    "        'RMSE': make_scorer(lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred)), greater_is_better=False),\n",
    "        'MAE': make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "        'R2': 'r2'\n",
    "    }\n",
    "\n",
    "    # Create pipeline with only the regressor\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "\n",
    "    # Configure GridSearchCV\n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid={'regressor__' + k: v for k, v in param_grid.items()},  # Add regressor prefix\n",
    "        scoring=scoring,\n",
    "        refit='RMSE',  # Metric to choose best model\n",
    "        cv=cv,\n",
    "        n_jobs=n_jobs,\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    # Train model with hyperparameter tuning\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = grid.predict(X_val)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    val_metrics = {\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_val, y_val_pred)),\n",
    "        'MAE': mean_absolute_error(y_val, y_val_pred),\n",
    "        'R2': r2_score(y_val, y_val_pred)\n",
    "    }\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\n{model_name} Results\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Best parameters:\", grid.best_params_)\n",
    "    print(f\"Validation RMSE: {val_metrics['RMSE']:.4f}\")\n",
    "    print(f\"Validation MAE: {val_metrics['MAE']:.4f}\")\n",
    "    print(f\"Validation R2: {val_metrics['R2']:.4f}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    return grid.best_estimator_, val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/pipeline.py\", line 475, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py\", line 1167, in fit\n    X, y = self._validate_data(\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1263, in check_X_y\n    X = check_array(\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n    array = array.astype(new_dtype)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/generic.py\", line 6643, in astype\n    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/internals/managers.py\", line 430, in astype\n    return self.apply(\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/internals/managers.py\", line 363, in apply\n    applied = getattr(b, f)(**kwargs)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/internals/blocks.py\", line 758, in astype\n    new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/dtypes/astype.py\", line 237, in astype_array_safe\n    new_values = astype_array(values, dtype, copy=copy)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/dtypes/astype.py\", line 182, in astype_array\n    values = _astype_nansafe(values, dtype, copy=copy)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/dtypes/astype.py\", line 133, in _astype_nansafe\n    return arr.astype(dtype, copy=True)\nValueError: could not convert string to float: '0c59d09b6459dc36'\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/pipeline.py\", line 475, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py\", line 1167, in fit\n    X, y = self._validate_data(\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1263, in check_X_y\n    X = check_array(\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n    array = array.astype(new_dtype)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/generic.py\", line 6643, in astype\n    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/internals/managers.py\", line 430, in astype\n    return self.apply(\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/internals/managers.py\", line 363, in apply\n    applied = getattr(b, f)(**kwargs)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/internals/blocks.py\", line 758, in astype\n    new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/dtypes/astype.py\", line 237, in astype_array_safe\n    new_values = astype_array(values, dtype, copy=copy)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/dtypes/astype.py\", line 182, in astype_array\n    values = _astype_nansafe(values, dtype, copy=copy)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/dtypes/astype.py\", line 133, in _astype_nansafe\n    return arr.astype(dtype, copy=True)\nValueError: could not convert string to float: 'ab72911cefb60f2b'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 12\u001b[0m\n\u001b[1;32m      3\u001b[0m ridge_model \u001b[38;5;241m=\u001b[39m Ridge()\n\u001b[1;32m      5\u001b[0m param_grid_ridge \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1e-05\u001b[39m],\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit_intercept\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mTrue\u001b[39;00m],\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolver\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mFalse\u001b[39;00m]\n\u001b[1;32m     10\u001b[0m }\n\u001b[0;32m---> 12\u001b[0m best_ridge, metrics_ridge \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_tune_regressor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mridge_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_grid_ridge\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRidge Regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     20\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 52\u001b[0m, in \u001b[0;36mtrain_and_tune_regressor\u001b[0;34m(model, param_grid, X_train, y_train, X_val, y_val, model_name, cv, n_jobs, verbose)\u001b[0m\n\u001b[1;32m     41\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     42\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mpipeline,\n\u001b[1;32m     43\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregressor__\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m param_grid\u001b[38;5;241m.\u001b[39mitems()},  \u001b[38;5;66;03m# Add regressor prefix\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Train model with hyperparameter tuning\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Evaluate on validation set\u001b[39;00m\n\u001b[1;32m     55\u001b[0m y_val_pred \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/model_selection/_search.py:947\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    943\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    944\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    945\u001b[0m     )\n\u001b[0;32m--> 947\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:536\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    530\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    531\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    535\u001b[0m     )\n\u001b[0;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    539\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/pipeline.py\", line 475, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py\", line 1167, in fit\n    X, y = self._validate_data(\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1263, in check_X_y\n    X = check_array(\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n    array = array.astype(new_dtype)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/generic.py\", line 6643, in astype\n    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/internals/managers.py\", line 430, in astype\n    return self.apply(\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/internals/managers.py\", line 363, in apply\n    applied = getattr(b, f)(**kwargs)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/internals/blocks.py\", line 758, in astype\n    new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/dtypes/astype.py\", line 237, in astype_array_safe\n    new_values = astype_array(values, dtype, copy=copy)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/dtypes/astype.py\", line 182, in astype_array\n    values = _astype_nansafe(values, dtype, copy=copy)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/dtypes/astype.py\", line 133, in _astype_nansafe\n    return arr.astype(dtype, copy=True)\nValueError: could not convert string to float: '0c59d09b6459dc36'\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/pipeline.py\", line 475, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py\", line 1167, in fit\n    X, y = self._validate_data(\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1263, in check_X_y\n    X = check_array(\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n    array = array.astype(new_dtype)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/generic.py\", line 6643, in astype\n    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/internals/managers.py\", line 430, in astype\n    return self.apply(\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/internals/managers.py\", line 363, in apply\n    applied = getattr(b, f)(**kwargs)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/internals/blocks.py\", line 758, in astype\n    new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/dtypes/astype.py\", line 237, in astype_array_safe\n    new_values = astype_array(values, dtype, copy=copy)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/dtypes/astype.py\", line 182, in astype_array\n    values = _astype_nansafe(values, dtype, copy=copy)\n  File \"/opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages/pandas/core/dtypes/astype.py\", line 133, in _astype_nansafe\n    return arr.astype(dtype, copy=True)\nValueError: could not convert string to float: 'ab72911cefb60f2b'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_model = Ridge()\n",
    "\n",
    "param_grid_ridge = {\n",
    "    'alpha': [1e-05],\n",
    "    'fit_intercept': [True],\n",
    "    'solver': ['auto'],\n",
    "    'positive': [False]\n",
    "}\n",
    "\n",
    "best_ridge, metrics_ridge = train_and_tune_regressor(\n",
    "    model=ridge_model,\n",
    "    param_grid=param_grid_ridge,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_test,\n",
    "    y_val=y_test,\n",
    "    model_name='Ridge Regression'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_workshop",
   "language": "python",
   "name": "nlp_workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
